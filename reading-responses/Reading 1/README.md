# Reading Response 1

### How data changes / will change

The word data originally came from Latin, meaning “a thing given” or “a gift sent by God”. After that it represents the given conditions in math. Later computers dramatically changed our understanding of data, which then mainly referred to electronic bits and bytes. Despite the radical changes in its definition, for a long time we considered data as “truth”, which is known by default and allows us to make inferences about the unknown.

It’s interesting that we could observe the semantic journey of the word “data” in history by looking at its linguistic neighbors, which reflect people’s attitudes towards data– how we first feel optimistic about big data, and then start to challenge it and critique its cultural and social implications. **Overall I see a great improvement on individuals’ data consciousness–more and more people start to understand and reflect on data.** Therefore I believe that positive words like **“autonomy” “personal”**and **“intimacy”** will become the linguistic neighbors of data in the future. **I’m not trying to deny the “mass” nature of data, but instead to propose an ideal envision on the significance of data at personal level,** just as the reading mentions, “now we often become the objects of data collection instead of the subjects”.

### Data bias

For me, data bias means that we tend to consider data as divine so that we neglect the social and cultural construct on data as well as the deeply embedded bias behind. That bias could be racial, gender or towards any marginalized groups. And I think data bias also comes from the idea of **“grouping”** and **“average representation”**. A simple example could be our visualization of weird food in class. If I give 1 point for durian while someone gives 5 points, the average point of 3 is meaningless since it cannot represent any of our real thoughts. Of course the real scenarios will be much more complicated than 6 people filling out a simple google form–like it will first use sophisticated algorithms to put you into a specific group, **but the idea that the big data tends to average people out and ignores the marginalized individual voice remains the same**. And I think this coincides with the idea that “data is reductive”– we need to simplify data in order to form some data-driven decisions/statements, and it is us that decide whose voices to be heard and who's not.